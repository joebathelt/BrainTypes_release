{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from CALM_utils import get_imaging_ID\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr, sem, ttest_ind, zscore\n",
    "import seaborn as sns\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bct\n",
    "import networkfunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams  \n",
    "rcParams['font.family'] = 'serif'  \n",
    "rcParams['font.serif'] = ['Computer Modern Unicode']  \n",
    "rcParams['text.usetex'] = True  \n",
    "rcParams['axes.labelsize'] = 9  \n",
    "rcParams['xtick.labelsize'] = 9  \n",
    "rcParams['ytick.labelsize'] = 9  \n",
    "rcParams['legend.fontsize'] = 9  \n",
    "mm2inches = 0.039371\n",
    "single_column = 90*mm2inches\n",
    "double_column = 190*mm2inches\n",
    "one_half_column = 140*mm2inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_consensus_module_assignment(network, iterations):\n",
    "    #================================\n",
    "    # Obtain the consensus module structure\n",
    "    #================================\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "    adjacency_matrix: adjacency_matrix\n",
    "    gamma: gamma value\n",
    "\n",
    "    outputs:\n",
    "    vector of module assignment for each node\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    consensus_matrices = list()\n",
    "\n",
    "    for i in range(0,iterations):\n",
    "        consensus_matrix,modules,q = get_consensus_matrix(network)\n",
    "        consensus_matrices.append(consensus_matrix)\n",
    "\n",
    "    mean_consensus_matrix = np.mean(consensus_matrices,axis=0)\n",
    "\n",
    "    consensus_matrix,modules,q = get_consensus_matrix(mean_consensus_matrix)\n",
    "    consensus_matrix2,modules,q = get_consensus_matrix(mean_consensus_matrix)\n",
    "\n",
    "    while abs(np.sum(consensus_matrix - consensus_matrix2)) != 0:\n",
    "        consensus_matrix,modules,q = get_consensus_matrix(mean_consensus_matrix)\n",
    "        consensus_matrix2,modules,q = get_consensus_matrix(mean_consensus_matrix)\n",
    "\n",
    "    return (modules, q)\n",
    "\n",
    "def get_consensus_matrix(network):\n",
    "    import bct\n",
    "    import numpy as np\n",
    "    modules,q = bct.modularity_louvain_und_sign(network, qtype='smp')\n",
    "    module_matrix = np.repeat(modules,repeats=network.shape[0])\n",
    "    module_matrix = np.reshape(module_matrix,newshape=network.shape)\n",
    "    consensus_matrix = module_matrix == module_matrix.transpose()\n",
    "    return (consensus_matrix.astype('float'), modules, q)\n",
    "\n",
    "def plot_matrix(network):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "    plt.figure(figsize=(one_half_column/2, one_half_column/2), dpi=300)\n",
    "    im = plt.imshow(network, \n",
    "               cmap='bwr',\n",
    "               interpolation='none',\n",
    "               vmin=-1, vmax=1)\n",
    "    ax = plt.gca()\n",
    "    ax.grid('off')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cb = plt.colorbar(im, cax=cax)\n",
    "    cb.set_label('Pearson correlation coefficient R')\n",
    "    cb.ax.yaxis.set_label_position('right')\n",
    "    plt.tight_layout(pad=0, w_pad=1, h_pad=0)\n",
    "    \n",
    "def plot_community_matrix(network, community_affiliation):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "    sorting_array = sorted(range(len(community_affiliation)), key=lambda k: community_affiliation[k])\n",
    "    sorted_network = network[sorting_array, :]\n",
    "    sorted_network = sorted_network[:, sorting_array]\n",
    "    plt.figure(figsize=(one_half_column/2, one_half_column/2), dpi=300)\n",
    "    im = plt.imshow(sorted_network, \n",
    "               cmap='bwr',\n",
    "               interpolation='none',\n",
    "               vmin=-1, vmax=1)\n",
    "    ax = plt.gca()\n",
    "    ax.grid('off')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cb = plt.colorbar(im, cax=cax)\n",
    "    cb.set_label('Pearson correlation coefficient R')\n",
    "    cb.ax.yaxis.set_label_position('right')\n",
    "    plt.tight_layout(pad=0, w_pad=1, h_pad=0)\n",
    "    \n",
    "def load_data(subject, measure, parcellation):\n",
    "    \n",
    "    if parcellation == 'HCP':\n",
    "        parcellation_name = ['HCP.fsaverage.aparc_source_subject_fsaverage_copy', 'HCP.fsaverage.aparc']\n",
    "    elif parcellation == '500':\n",
    "        parcellation_name = ['500.aparc_source_subject_fsaverageSubP', '500.aparc']\n",
    "    elif parcellation == 'a2009s':\n",
    "        parcellation_name = ['aparc.a2009s_source_subject_fsaverage_copy', 'aparc.a2009s']\n",
    "    elif parcellation == 'Yeo':\n",
    "        parcellation_name = ['Yeo2011_7Networks_N1000_source_subject_fsaverageSubP', 'Yeo2011_7Networks_N1000']\n",
    "    else:\n",
    "        print('Must be one of HCP, a2009s, 500, Yeo')\n",
    "        \n",
    "    filename = '/imaging/jb07/CALM/Morphological_Covariance/morphological_covariance_pipeline/_subject_id_' + subject + '/_source_annot_file_' + parcellation_name[0] + '/'\n",
    "\n",
    "    if measure in ['FA', 'MD', 'AD', 'RD']:\n",
    "        filename = filename + measure + '_atlas_values/' + subject + '_' + measure + '_flirt_' + measure + '_' + parcellation_name[1] + '_cortical_expanded_consecutive.csv'\n",
    "        if os.path.isfile(filename):\n",
    "            data = pd.read_csv(filename)['value'].values\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    if measure in ['CurvInd', 'FoldInd', 'GausCurv', 'GrayVol', 'MeanCurv', 'SurfArea', 'ThickAvg', 'ThickStd']:\n",
    "        filename = filename + '/freesurfer_values/' + parcellation_name[1] + '_' + measure + '.csv'\n",
    "        if os.path.isfile(filename):\n",
    "            data = pd.read_csv(filename)['value'].values\n",
    "        else:\n",
    "            return []\n",
    "    \n",
    "    data = np.asarray(data)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def plot_cognitive_differences(analysis_df, binarized_results):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_style({'axes.grid': False,\n",
    "                       'font.family': [u'serif'],\n",
    "                       'font.sans-serif': [u'Computer Modern Unicode'],})\n",
    "    colours = ['turquoise', 'gold', 'firebrick', 'limegreen', 'darkorange', 'deepskyblue']\n",
    "    labels = ['Spelling', 'Reading', 'Maths', 'MatrixReasoning', 'Vocabulary', 'DigitRecall', 'DotMatrix', 'BackwardDigit', 'MrX', 'StoryRecall']\n",
    "\n",
    "    plt.figure(figsize=(one_half_column, one_half_column), dpi=600)\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "\n",
    "    for group in np.unique(analysis_df['groups']):\n",
    "        mean = analysis_df[analysis_df['groups'] == group].mean()[measures]\n",
    "        SE = analysis_df[analysis_df['groups'] == group].mean()[measures]\n",
    "        plt.errorbar(x=np.arange(0,len(measures)),\n",
    "                     y=mean, yerr=2*SE, \n",
    "                     color=colours[group-1])\n",
    "\n",
    "    plt.xlim([-0.5,len(mean)-0.5])\n",
    "    plt.xticks(range(0,len(mean)))\n",
    "    plt.legend(['C' + str(community) for community in sorted(np.unique(analysis_df['groups']))], frameon=True, loc='best')\n",
    "    plt.ylabel('z-score')\n",
    "    ax = plt.gca()\n",
    "    ax.set_xticklabels('', rotation=90);\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    combinations = list(itertools.combinations(np.unique(analysis_df['groups']), 2))\n",
    "\n",
    "    new_style = {'grid': False}\n",
    "    matplotlib.rc('axes', **new_style)\n",
    "    plt.imshow(binarized_results, \n",
    "              interpolation = 'none', \n",
    "              cmap=LinearSegmentedColormap.from_list('mycmap', [(0, 'lightgray'), (1, 'orangered')]))\n",
    "    plt.yticks(np.arange(0,len(combinations)))\n",
    "    plt.xticks(np.arange(0, len(mean)))\n",
    "    plt.ylabel('contrast results')\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_yticklabels([str(combination[0]) + ' v ' + str(combination[1]) for combination in combinations], rotation=0);\n",
    "    ax.set_xticklabels(labels, rotation=90);\n",
    "    plt.tight_layout(pad=0, w_pad=0, h_pad=0)\n",
    "    plt.show()\n",
    "    \n",
    "def get_quality_index(subject_list, brain_measure, parcellation):\n",
    "    data = get_data_from_all_subjects(subject_list, brain_measure, parcellation)\n",
    "    correlation_matrix = data.transpose().corr().values\n",
    "    community_affiliation,q = get_consensus_module_assignment(correlation_matrix, 100)\n",
    "    data.columns = ['region_' + str(column) for column in data.columns]\n",
    "    data['groups'] = community_affiliation\n",
    "    \n",
    "    return (data, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "behavioural_df = pd.read_csv('../data/raw_data/CALM_behavioural_data_Apr17.csv')\n",
    "behavioural_df = behavioural_df[behavioural_df['ID No.'].isin(behavioural_df['ID No.'].dropna())]\n",
    "behavioural_df['MRI.ID'] = [get_imaging_ID(str(int(ID))) for ID in behavioural_df['ID No.']]\n",
    "measures = ['Conners_inattention_raw',\n",
    "        'Conners_hyperactivity_impulsivity_raw',\n",
    "        'Conners_learning_problems_raw',\n",
    "        'Conners_ExecutiveFunction_raw',\n",
    "        'Conners_agression_raw',\n",
    "        'Conners_PeerRelations_raw']\n",
    "analysis_df = behavioural_df[np.hstack([['MRI.ID', 'Age_in_months', 'Gender(1=male)'], measures])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop missing values \n",
    "analysis_df = analysis_df.dropna()\n",
    "\n",
    "# Regress the effect of age\n",
    "for measure in measures:\n",
    "    analysis_df[measure] = ols(measure + ' ~ Age_in_months', data=analysis_df).fit().resid\n",
    "\n",
    "# Z-transform\n",
    "analysis_df[measures] = analysis_df[measures].apply(zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "in_folder = '/imaging/jb07/CALM/Modularity/connectome/'\n",
    "filename = lambda(subject): in_folder + '_subject_id_' + subject + '/_model_CSA/_threshold_10/calc_matrix/mapflow/_calc_matrix0/' + subject + '_FA_matrix.txt'\n",
    "subject_list = sorted([subject for subject in analysis_df['MRI.ID'].values if os.path.isfile(filename(subject))])\n",
    "analysis_df = analysis_df[analysis_df['MRI.ID'].isin(subject_list)]\n",
    "networks = np.rollaxis(np.asarray([np.loadtxt(filename(subject)) for subject in subject_list]), 0, 3)\n",
    "np.place(networks, np.isnan(networks), 0) # replacing nan values\n",
    "\n",
    "# Removing regions that are not of interest\n",
    "aparc_indices = networkfunctions.aparc_indices('/imaging/jb07/CALM/Modularity/connectome/FreeSurfer/CBU150084/parcellation/aparc_expanded.nii.gz')\n",
    "new_networks = list()\n",
    "\n",
    "for counter in range(0,networks.shape[2]):\n",
    "    network = networks[..., counter]\n",
    "    network = network[aparc_indices, ...]\n",
    "    network = network[..., aparc_indices]\n",
    "    new_networks.append(np.squeeze(network))\n",
    "\n",
    "networks = np.rollaxis(np.asarray(new_networks), 0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connectome_measure = np.asarray([bct.strengths_und(networks[...,i]) for i in np.arange(0, networks.shape[2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for region in np.arange(connectome_measure.shape[1]):\n",
    "    temp_df = pd.DataFrame({'y': connectome_measure[:,region], 'x': analysis_df['Age_in_months'].values})\n",
    "    connectome_measure[:, region] = ols('y ~ x', data=temp_df).fit().resid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Build the model based on typical cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = connectome_measure\n",
    "y = analysis_df[measures[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting into a training, validation, and test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "x_train, x_validate, y_train, y_validate = train_test_split(x_train, y_train, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'axis' entry is out of bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-8539bed629d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfeature_selection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mspearmanr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mregion\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mselected_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselected_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/jb07/python_modules/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   1838\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1839\u001b[0m         return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[1;32m-> 1840\u001b[1;33m                              out=out, keepdims=keepdims)\n\u001b[0m\u001b[0;32m   1841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jb07/python_modules/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 'axis' entry is out of bounds"
     ]
    }
   ],
   "source": [
    "# Selecting features that correlate with the outcome\n",
    "feature_selection = np.asarray([spearmanr(x_train, y_train)[1] for region in np.arange(0, x_train.shape[1])])\n",
    "selected_features = np.where(feature_selection < 0.05)[0]\n",
    "x_train = np.sum(x_train[:, selected_features], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 24 Jun 2017</td> <th>  Prob (F-statistic):</th>  <td>0.0955</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:56:35</td>     <th>  Log-Likelihood:    </th> <td> -220.54</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   148</td>      <th>  AIC:               </th> <td>   445.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   146</td>      <th>  BIC:               </th> <td>   451.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   -0.0972</td> <td>    0.089</td> <td>   -1.094</td> <td> 0.276</td> <td>   -0.273</td> <td>    0.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x</th>         <td> 3.664e-06</td> <td> 2.18e-06</td> <td>    1.678</td> <td> 0.095</td> <td>-6.52e-07</td> <td> 7.98e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>14.803</td> <th>  Durbin-Watson:     </th> <td>   1.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  17.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.829</td> <th>  Prob(JB):          </th> <td>0.000184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.801</td> <th>  Cond. No.          </th> <td>4.07e+04</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.019\n",
       "Model:                            OLS   Adj. R-squared:                  0.012\n",
       "Method:                 Least Squares   F-statistic:                     2.816\n",
       "Date:                Sat, 24 Jun 2017   Prob (F-statistic):             0.0955\n",
       "Time:                        10:56:35   Log-Likelihood:                -220.54\n",
       "No. Observations:                 148   AIC:                             445.1\n",
       "Df Residuals:                     146   BIC:                             451.1\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -0.0972      0.089     -1.094      0.276      -0.273       0.078\n",
       "x           3.664e-06   2.18e-06      1.678      0.095   -6.52e-07    7.98e-06\n",
       "==============================================================================\n",
       "Omnibus:                       14.803   Durbin-Watson:                   1.907\n",
       "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               17.199\n",
       "Skew:                          -0.829   Prob(JB):                     0.000184\n",
       "Kurtosis:                       2.801   Cond. No.                     4.07e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.07e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ols('y ~ x', data= pd.DataFrame({'x': x, 'y': y})).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
